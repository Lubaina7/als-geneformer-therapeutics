{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8282597d",
   "metadata": {},
   "source": [
    "# Task 1: Design In-Silico Perturbation Workflow\n",
    "\n",
    "**Objective**: Design and validate a reusable perturbation framework\n",
    "\n",
    "**Key Features**:\n",
    "- Multiplicative knock-down and knock-up\n",
    "- Cell-type specific targeting capability\n",
    "- Scalable to multiple genes\n",
    "- Quality validation with biological plausibility checks\n",
    "\n",
    "**Note**: This task demonstrates the workflow with 2-3 genes. Task 2 will apply it to full ALS gene set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9310057",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Setup and Path Configuration"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/lubainakothari/Desktop/perturbation_newstructure\n",
      "✓ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# ============================================\n",
    "# FLEXIBLE PATH HANDLING\n",
    "# ============================================\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "if NOTEBOOK_DIR.name == 'notebooks':\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "import sys\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from utils.perturbation import GenePerturbationWorkflow, PerturbationValidator\n",
    "from utils.data_io import DataIOManager\n",
    "from utils.smoke_tests import SmokeTestRunner\n",
    "from utils import visualization as viz\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4902b1a",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Load Configuration"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config loaded from: /Users/lubainakothari/Desktop/perturbation_newstructure/config/config.yaml\n",
      "\n",
      "Configuration:\n",
      "  Smoke test: False\n",
      "  Random seed: 0\n",
      "  Results: /Users/lubainakothari/Desktop/perturbation_newstructure/results/task1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================\n",
    "# LOAD CONFIG.YAML\n",
    "# ============================================\n",
    "config_path = PROJECT_ROOT / \"config\" / \"config.yaml\"\n",
    "\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(f\"Config not found: {config_path}\")\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"✓ Config loaded from: {config_path}\")\n",
    "\n",
    "# Extract settings\n",
    "SMOKE_TEST = config['smoke_test']['enabled']\n",
    "RANDOM_SEED = config['random_seed']\n",
    "ALS_GENES = config['als_genes']  \n",
    "\n",
    "# Set paths\n",
    "DATA_PATH = PROJECT_ROOT / config['data']['raw_data_path']\n",
    "CACHE_DIR = PROJECT_ROOT / config['data']['cache_dir']\n",
    "RESULTS_DIR = PROJECT_ROOT / config['data']['results_dir']\n",
    "\n",
    "# Create organized output structure for Task 1\n",
    "TASK1_DIR = RESULTS_DIR / \"task1\"\n",
    "TABLES_DIR = TASK1_DIR / \"tables\"\n",
    "FIGURES_DIR = TASK1_DIR / \"figures\"\n",
    "\n",
    "for dir_path in [CACHE_DIR, TASK1_DIR, TABLES_DIR, FIGURES_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Configure plotting\n",
    "sc.settings.verbosity = 1\n",
    "sc.settings.set_figure_params(\n",
    "    dpi=config['visualization']['figure_dpi'],\n",
    "    facecolor='white'\n",
    ")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Smoke test: {SMOKE_TEST}\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")\n",
    "print(f\"  Results: {TASK1_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d5757",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f33de2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 FULL PIPELINE MODE\n",
      "DataIOManager initialized\n",
      "  Data directory: /Users/lubainakothari/Desktop/perturbation_newstructure/data\n",
      "  Cache directory: /Users/lubainakothari/Desktop/perturbation_newstructure/cache\n",
      "Loading data from: /Users/lubainakothari/Desktop/perturbation_newstructure/data/counts_combined_filtered_BA4_sALS_PN.h5ad\n",
      "  Loading fully into memory...\n",
      "✓ Loaded: 112,014 cells × 22,832 genes\n",
      "\n",
      "Data loaded:\n",
      "  Cells: 112,014\n",
      "  Genes: 22,832\n",
      "\n",
      "Condition distribution:\n",
      "Condition\n",
      "ALS    66960\n",
      "PN     45054\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if SMOKE_TEST:\n",
    "    print(\"\\n🔥 SMOKE TEST MODE\")\n",
    "    print(f\"Using {config['smoke_test']['n_cells']} cells × {config['smoke_test']['n_genes']} genes\\n\")\n",
    "    \n",
    "    runner = SmokeTestRunner(str(DATA_PATH))\n",
    "    adata = runner.create_smoke_test_subset(\n",
    "        n_cells=config['smoke_test']['n_cells'],\n",
    "        n_genes=config['smoke_test']['n_genes'],\n",
    "        save_path=str(CACHE_DIR / \"smoke_test_subset.h5ad\")\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n📊 FULL PIPELINE MODE\")\n",
    "    \n",
    "    io_manager = DataIOManager(\n",
    "        base_dir=str(PROJECT_ROOT / \"data\"),\n",
    "        cache_dir=str(CACHE_DIR)\n",
    "    )\n",
    "    adata = io_manager.load_adata_efficient(str(DATA_PATH), backed=False)\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Cells: {adata.n_obs:,}\")\n",
    "print(f\"  Genes: {adata.n_vars:,}\")\n",
    "\n",
    "if 'Condition' in adata.obs.columns:\n",
    "    print(f\"\\nCondition distribution:\")\n",
    "    print(adata.obs['Condition'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41436e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 2. Select Demo Genes\n",
    "\n",
    "For workflow demonstration, we'll use **2-3 high-variance genes** from the dataset.\n",
    "Task 2 will apply the workflow to the full ALS gene set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83378c5e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SELECTING DEMO GENES\n",
      "======================================================================\n",
      "\n",
      "Full pipeline: Looking for ALS genes...\n",
      "Demo genes selected: ['SOD1', 'C9orf72', 'TARDBP']\n",
      "\n",
      "Note: These are for workflow validation only.\n",
      "      Task 2 will apply to full ALS gene set.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SELECTING DEMO GENES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if SMOKE_TEST:\n",
    "    # Smoke test: First 3 genes in the subset\n",
    "    demo_genes = list(adata.var_names[:3])\n",
    "    print(f\"\\nSmoke test: Using first 3 genes from subset\")\n",
    "else:\n",
    "    # Full pipeline: First 2-3 ALS genes found in dataset\n",
    "    print(f\"\\nFull pipeline: Looking for ALS genes...\")\n",
    "    \n",
    "    # Get first 2-3 ALS genes that exist in dataset\n",
    "    demo_genes = []\n",
    "    for gene in ALS_GENES:\n",
    "        if gene in adata.var_names:\n",
    "            demo_genes.append(gene)\n",
    "            if len(demo_genes) == 3:\n",
    "                break\n",
    "    \n",
    "    # Fallback: if no ALS genes found, use first 3 genes\n",
    "    if len(demo_genes) == 0:\n",
    "        print(\"  No ALS genes found - using first 3 genes as fallback\")\n",
    "        demo_genes = list(adata.var_names[:3])\n",
    "\n",
    "print(f\"Demo genes selected: {demo_genes}\")\n",
    "print(f\"\\nNote: These are for workflow validation only.\")\n",
    "print(f\"      Task 2 will apply to full ALS gene set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9f960",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 3. Initialize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79c8c79",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GenePerturbationWorkflow initialized\n",
      "  Cells: 112,014\n",
      "  Genes: 22,832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "workflow = GenePerturbationWorkflow(adata, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240fb44b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 4. Demonstrate Perturbation Capabilities\n",
    "\n",
    "Show the workflow can handle:\n",
    "- Knock-down (reduce expression)\n",
    "- Knock-up (increase expression)\n",
    "- Different perturbation strengths\n",
    "- Cell-type specific targeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab1f26c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "KNOCK-DOWN DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "Demonstrating knock-down on 3 genes\n",
      "Reduction factors: [0.2, 0.5]\n",
      "✓ Knock-down: 1 gene(s), 112,014 cells\n",
      "  Reduction: 80% (log2FC = -2.32)\n",
      "  ✓ DEMO_KD_SOD1_0.2\n",
      "✓ Knock-down: 1 gene(s), 112,014 cells\n",
      "  Reduction: 50% (log2FC = -1.00)\n",
      "  ✓ DEMO_KD_SOD1_0.5\n",
      "✓ Knock-down: 1 gene(s), 112,014 cells\n",
      "  Reduction: 80% (log2FC = -2.32)\n",
      "  ✓ DEMO_KD_C9orf72_0.2\n",
      "✓ Knock-down: 1 gene(s), 112,014 cells\n",
      "  Reduction: 50% (log2FC = -1.00)\n",
      "  ✓ DEMO_KD_C9orf72_0.5\n",
      "✓ Knock-down: 1 gene(s), 112,014 cells\n",
      "  Reduction: 80% (log2FC = -2.32)\n",
      "  ✓ DEMO_KD_TARDBP_0.2\n",
      "✓ Knock-down: 1 gene(s), 112,014 cells\n",
      "  Reduction: 50% (log2FC = -1.00)\n",
      "  ✓ DEMO_KD_TARDBP_0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KNOCK-DOWN DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "kd_factors = config['perturbation']['knock_down']['factors'][:2]\n",
    "\n",
    "print(f\"\\nDemonstrating knock-down on {len(demo_genes)} genes\")\n",
    "print(f\"Reduction factors: {kd_factors}\")\n",
    "\n",
    "for gene in demo_genes:\n",
    "    for factor in kd_factors:\n",
    "        pert_id = workflow.knock_down(\n",
    "            genes=gene,\n",
    "            reduction_factor=factor,\n",
    "            perturbation_id=f'DEMO_KD_{gene}_{factor:.1f}',\n",
    "            seed=RANDOM_SEED\n",
    "        )\n",
    "        print(f\"  ✓ {pert_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59e6ced",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "KNOCK-UP DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "Demonstrating knock-up on 3 genes\n",
      "Amplification factors: [2.0, 3.0]\n",
      "✓ Knock-up: 1 gene(s), 112,014 cells\n",
      "  Amplification: 2.0x (log2FC = 1.00)\n",
      "  ✓ DEMO_KU_SOD1_2.0\n",
      "✓ Knock-up: 1 gene(s), 112,014 cells\n",
      "  Amplification: 3.0x (log2FC = 1.58)\n",
      "  ✓ DEMO_KU_SOD1_3.0\n",
      "✓ Knock-up: 1 gene(s), 112,014 cells\n",
      "  Amplification: 2.0x (log2FC = 1.00)\n",
      "  ✓ DEMO_KU_C9orf72_2.0\n",
      "✓ Knock-up: 1 gene(s), 112,014 cells\n",
      "  Amplification: 3.0x (log2FC = 1.58)\n",
      "  ✓ DEMO_KU_C9orf72_3.0\n",
      "✓ Knock-up: 1 gene(s), 112,014 cells\n",
      "  Amplification: 2.0x (log2FC = 1.00)\n",
      "  ✓ DEMO_KU_TARDBP_2.0\n",
      "✓ Knock-up: 1 gene(s), 112,014 cells\n",
      "  Amplification: 3.0x (log2FC = 1.58)\n",
      "  ✓ DEMO_KU_TARDBP_3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KNOCK-UP DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ku_factors = config['perturbation']['knock_up']['factors'][:2]\n",
    "ku_noise = config['perturbation']['knock_up']['noise_level']\n",
    "ku_min_expr = config['perturbation']['knock_up']['min_expr']\n",
    "\n",
    "print(f\"\\nDemonstrating knock-up on {len(demo_genes)} genes\")\n",
    "print(f\"Amplification factors: {ku_factors}\")\n",
    "\n",
    "for gene in demo_genes:\n",
    "    for factor in ku_factors:\n",
    "        pert_id = workflow.knock_up(\n",
    "            genes=gene,\n",
    "            amplification_factor=factor,\n",
    "            noise_level=ku_noise,\n",
    "            min_expr=ku_min_expr,\n",
    "            perturbation_id=f'DEMO_KU_{gene}_{factor:.1f}',\n",
    "            seed=RANDOM_SEED\n",
    "        )\n",
    "        print(f\"  ✓ {pert_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c668ce5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONDITION-SPECIFIC DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "Demonstrating ALS-specific perturbation: 66,960 cells\n",
      "✓ Knock-down: 1 gene(s), 66,960 cells\n",
      "  Reduction: 50% (log2FC = -1.00)\n",
      "  ✓ DEMO_KD_SOD1_ALS\n",
      "\n",
      "Demonstrating PN-specific perturbation: 45,054 cells\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONDITION-SPECIFIC DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'Condition' in adata.obs.columns:\n",
    "    als_mask = adata.obs['Condition'] == 'ALS'\n",
    "    pn_mask = adata.obs['Condition'] == 'PN'\n",
    "    \n",
    "    if als_mask.sum() > 0:\n",
    "        print(f\"\\nDemonstrating ALS-specific perturbation: {als_mask.sum():,} cells\")\n",
    "        pert_id = workflow.knock_down(\n",
    "            genes=demo_genes[0],\n",
    "            reduction_factor=0.5,\n",
    "            cell_subset=als_mask,\n",
    "            perturbation_id=f'DEMO_KD_{demo_genes[0]}_ALS',\n",
    "            seed=RANDOM_SEED\n",
    "        )\n",
    "        print(f\"  ✓ {pert_id}\")\n",
    "    \n",
    "    if pn_mask.sum() > 0:\n",
    "        print(f\"\\nDemonstrating PN-specific perturbation: {pn_mask.sum():,} cells\")\n",
    "        pert_id = workflow.knock_down(\n",
    "            genes=demo_genes[0],\n",
    "            reduction_factor=0.5,\n",
    "            cell_subset=pn_mask,\n",
    "            perturbation_id=f'DEMO_KD_{demo_genes[0]}_PN',\n",
    "            seed=RANDOM_SEED\n",
    "        )\n",
    "        print(f\"  ✓ {pert_id}\")\n",
    "else:\n",
    "    print(\"  Skipped (no Condition column)\")\n",
    "\n",
    "print(f\"\\n✓ Total demo perturbations: {len(workflow.perturbed_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b889b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 5. Workflow Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ce1b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "summary_df = workflow.get_perturbation_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"WORKFLOW DEMONSTRATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(summary_df[['id', 'type', 'genes', 'factor', 'log2_effect', 'n_cells']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n✓ Workflow capabilities demonstrated:\")\n",
    "print(f\"  • Knock-downs: {(summary_df['type'] == 'knock_down').sum()}\")\n",
    "print(f\"  • Knock-ups: {(summary_df['type'] == 'knock_up').sum()}\")\n",
    "print(f\"  • Genes tested: {summary_df['genes'].apply(lambda x: x[0]).nunique()}\")\n",
    "print(f\"  • Condition-specific: {summary_df['id'].str.contains('ALS|PN').sum()}\")\n",
    "\n",
    "# Save summary\n",
    "summary_path = TABLES_DIR / \"workflow_demo_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\n✓ Summary saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f82f5f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 6. Validation\n",
    "\n",
    "Validate that perturbations achieve expected biological effects.\n",
    "Separate validation for standard and condition-specific perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87c462",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FOLD-CHANGE VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "validator = PerturbationValidator()\n",
    "validation_results = []\n",
    "\n",
    "# Validate all demo perturbations\n",
    "print(f\"\\nValidating all {len(workflow.perturbed_data)} demo perturbations...\\n\")\n",
    "\n",
    "for pert_id in workflow.perturbed_data.keys():\n",
    "    adata_pert = workflow.get_perturbation(pert_id)\n",
    "    gene_name = adata_pert.uns['perturbation']['genes'][0]\n",
    "    \n",
    "    metrics = validator.validate_perturbation_strength(adata, adata_pert, gene_name)\n",
    "    \n",
    "    expected_log2fc = adata_pert.uns['perturbation']['log2_effect']\n",
    "    actual_log2fc = metrics['log2_fold_change']\n",
    "    fc_match = abs(actual_log2fc - expected_log2fc) < config['validation']['fold_change_tolerance']\n",
    "    \n",
    "    # Determine if condition-specific\n",
    "    is_condition_specific = 'ALS' in pert_id or 'PN' in pert_id\n",
    "    condition = None\n",
    "    if 'ALS' in pert_id:\n",
    "        condition = 'ALS'\n",
    "    elif 'PN' in pert_id:\n",
    "        condition = 'PN'\n",
    "    \n",
    "    print(f\"{pert_id}:\")\n",
    "    print(f\"  Expected log2FC: {expected_log2fc:.2f}\")\n",
    "    print(f\"  Actual log2FC:   {actual_log2fc:.2f}\")\n",
    "    print(f\"  Match: {'✓' if fc_match else '✗'}\")\n",
    "    \n",
    "    checks = validator.check_biological_plausibility(adata_pert)\n",
    "    all_passed = all(checks.values())\n",
    "    \n",
    "    if all_passed:\n",
    "        print(f\"  Plausibility: ✓ PASS\\n\")\n",
    "    else:\n",
    "        print(f\"  Plausibility: ✗ FAIL\")\n",
    "        failed_checks = [check for check, passed in checks.items() if not passed]\n",
    "        print(f\"    Failed: {', '.join(failed_checks)}\\n\")\n",
    "    \n",
    "    validation_results.append({\n",
    "        'perturbation_id': pert_id,\n",
    "        'gene': gene_name,\n",
    "        'expected_log2fc': expected_log2fc,\n",
    "        'actual_log2fc': actual_log2fc,\n",
    "        'fc_match': fc_match,\n",
    "        'plausibility_pass': all_passed,\n",
    "        'failed_checks': ', '.join(failed_checks) if not all_passed else 'none',\n",
    "        'is_condition_specific': is_condition_specific,\n",
    "        'condition': condition,\n",
    "        'n_cells_perturbed': metrics['cells_affected']\n",
    "    })\n",
    "\n",
    "validation_df = pd.DataFrame(validation_results)\n",
    "\n",
    "# Save validation\n",
    "validation_path = TABLES_DIR / \"validation_results.csv\"\n",
    "validation_df.to_csv(validation_path, index=False)\n",
    "print(f\"✓ Validation saved: {validation_path}\")\n",
    "\n",
    "# Summary\n",
    "fc_pass_rate = validation_df['fc_match'].mean() * 100\n",
    "print(f\"\\nValidation Summary:\")\n",
    "print(f\"  Fold-change accuracy: {fc_pass_rate:.0f}% ({validation_df['fc_match'].sum()}/{len(validation_df)})\")\n",
    "print(f\"  → Perturbations achieve expected effects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87750ce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CONDITION-SPECIFIC VALIDATION ANALYSIS\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONDITION-SPECIFIC VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "condition_specific_df = validation_df[validation_df['is_condition_specific']]\n",
    "\n",
    "if len(condition_specific_df) > 0:\n",
    "    print(f\"\\nAnalyzing {len(condition_specific_df)} condition-specific perturbations:\\n\")\n",
    "    \n",
    "    # Compare ALS vs PN\n",
    "    for condition in ['ALS', 'PN']:\n",
    "        cond_data = condition_specific_df[condition_specific_df['condition'] == condition]\n",
    "        if len(cond_data) > 0:\n",
    "            print(f\"{condition} cells:\")\n",
    "            print(f\"  Perturbations: {len(cond_data)}\")\n",
    "            print(f\"  Cells affected: {cond_data['n_cells_perturbed'].iloc[0]}\")\n",
    "            print(f\"  FC match rate: {cond_data['fc_match'].mean()*100:.0f}%\")\n",
    "            print(f\"  Mean deviation: {(cond_data['actual_log2fc'] - cond_data['expected_log2fc']).abs().mean():.3f}\\n\")\n",
    "    \n",
    "    # Save condition-specific validation\n",
    "    condition_val_path = TABLES_DIR / \"condition_specific_validation.csv\"\n",
    "    condition_specific_df.to_csv(condition_val_path, index=False)\n",
    "    print(f\"✓ Condition-specific validation saved: {condition_val_path}\")\n",
    "else:\n",
    "    print(\"\\n  No condition-specific perturbations found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151263f6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e843b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Log2FC summary\n",
    "print(\"\\n1. Log2 fold-change summary\")\n",
    "fig = viz.plot_log2fc_summary(workflow, validation_df=validation_df)  # ← ADD validation_df\n",
    "save_path = FIGURES_DIR / 'demo_log2fc_summary.png'\n",
    "plt.savefig(save_path, dpi=config['visualization']['figure_dpi'], bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"   ✓ Saved: {save_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6580e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Example perturbation effect (first standard KD)\n",
    "print(\"\\n2. Example perturbation effect\")\n",
    "kd_perts = [k for k in workflow.perturbed_data.keys() \n",
    "            if 'KD' in k and 'ALS' not in k and 'PN' not in k]\n",
    "if kd_perts:\n",
    "    pert_id = kd_perts[0]\n",
    "    adata_pert = workflow.get_perturbation(pert_id)\n",
    "    gene_name = adata_pert.uns['perturbation']['genes'][0]\n",
    "    \n",
    "    fig = viz.plot_perturbation_effect(adata, adata_pert, gene_name)\n",
    "    save_path = FIGURES_DIR / f'demo_example_effect.png'\n",
    "    plt.savefig(save_path, dpi=config['visualization']['figure_dpi'], bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"   ✓ Saved: {save_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51610a7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3. Validation summary\n",
    "print(\"\\n3. Validation summary\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Fold-change accuracy\n",
    "ax = axes[0]\n",
    "validation_df['fc_deviation'] = validation_df['actual_log2fc'] - validation_df['expected_log2fc']\n",
    "validation_df_sorted = validation_df.sort_values('fc_deviation', key=lambda x: abs(x))\n",
    "colors = ['green' if x else 'red' for x in validation_df_sorted['fc_match']]\n",
    "x_pos = np.arange(len(validation_df_sorted))\n",
    "ax.bar(x_pos, validation_df_sorted['fc_deviation'], color=colors, alpha=0.7)\n",
    "ax.axhline(y=config['validation']['fold_change_tolerance'], color='red', linestyle='--', alpha=0.5,\n",
    "           label=f'±{config[\"validation\"][\"fold_change_tolerance\"]} tolerance')\n",
    "ax.axhline(y=-config['validation']['fold_change_tolerance'], color='red', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Perturbations (sorted by deviation)', fontsize=11)\n",
    "ax.set_ylabel('Deviation from Expected log2FC', fontsize=11)\n",
    "ax.set_title('Perturbation Strength Validation\\n(Does each perturbation achieve its target effect?)', \n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Pass rates\n",
    "ax = axes[1]\n",
    "\n",
    "# Calculate pass rates\n",
    "fc_pass_rate = (validation_df['fc_match'].sum() / len(validation_df)) * 100\n",
    "plausibility_pass_rate = (validation_df['plausibility_pass'].sum() / len(validation_df)) * 100\n",
    "\n",
    "# Create bar chart\n",
    "categories = ['Strength Match\\n(Target FC Achieved)', 'Biological Plausability\\n(No Artifacts from Perturbation)']\n",
    "values = [fc_pass_rate, plausibility_pass_rate]\n",
    "colors = ['steelblue', 'coral']\n",
    "\n",
    "y_pos = np.arange(len(categories))\n",
    "bars = ax.barh(y_pos, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(categories, fontsize=10)\n",
    "ax.set_xlabel('Pass Rate (%)', fontsize=11)\n",
    "ax.set_title('Validation Pass Rates\\n(What % of perturbations are valid?)', \n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.set_xlim(0, 105)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(values):\n",
    "    ax.text(v + 2, i, f'{v:.1f}%', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = FIGURES_DIR / 'demo_validation.png'\n",
    "plt.savefig(save_path, dpi=config['visualization']['figure_dpi'], bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"   ✓ Saved: {save_path.name}\")\n",
    "\n",
    "print(\"\\n✓ All visualizations complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f0b74",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7138d41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 8. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c662b5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TASK 1 COMPLETE - WORKFLOW VALIDATED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n📊 Workflow Demonstration:\")\n",
    "print(f\"   • Framework: GenePerturbationWorkflow class\")\n",
    "print(f\"   • Demo genes: {len(demo_genes)}\")\n",
    "print(f\"   • Total perturbations: {len(summary_df)}\")\n",
    "print(f\"     - Standard: {len(validation_df[~validation_df['is_condition_specific']])}\")\n",
    "print(f\"     - Condition-specific: {len(condition_specific_df)}\")\n",
    "print(f\"   • Validation pass rate: {fc_pass_rate:.0f}%\")\n",
    "\n",
    "print(f\"\\n✓ Key Capabilities Demonstrated:\")\n",
    "print(f\"   • Knock-down perturbations (multiple strengths)\")\n",
    "print(f\"   • Knock-up perturbations (with biological noise)\")\n",
    "print(f\"   • Condition-specific targeting (ALS/PN cells)\")\n",
    "print(f\"   • Scalable to multiple genes\")\n",
    "print(f\"   • Biologically validated\")\n",
    "\n",
    "print(f\"\\n📁 Outputs: {TASK1_DIR}/\")\n",
    "print(f\"   ├── tables/\")\n",
    "print(f\"   │   ├── workflow_demo_summary.csv\")\n",
    "print(f\"   │   ├── validation_results.csv\")\n",
    "print(f\"   │   └── condition_specific_validation.csv\")\n",
    "print(f\"   └── figures/\")\n",
    "print(f\"       ├── demo_log2fc_summary.png\")\n",
    "print(f\"       ├── demo_example_effect.png\")\n",
    "print(f\"       ├── demo_validation.png\")\n",
    "\n",
    "print(\"\\n🎯 Workflow Ready for Task 2:\")\n",
    "print(\"   The validated GenePerturbationWorkflow can now be applied to\")\n",
    "print(\"   the full ALS gene set with disease-specific cells.\")\n",
    "\n",
    "print(\"\\n➡️  Next: Run Task 2 to apply workflow to ALS genes + generate embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f8ab1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save report\n",
    "report_path = TABLES_DIR / 'task1_report.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\" * 70 + \"\\n\")\n",
    "    f.write(\"TASK 1: IN-SILICO PERTURBATION WORKFLOW\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Objective: Design and validate reusable perturbation framework\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Demo Configuration:\\n\")\n",
    "    f.write(f\"  Data: {adata.n_obs:,} cells × {adata.n_vars:,} genes\\n\")\n",
    "    f.write(f\"  Demo genes: {demo_genes}\\n\")\n",
    "    f.write(f\"  Perturbations: {len(summary_df)}\\n\")\n",
    "    f.write(f\"    - Standard: {len(validation_df[~validation_df['is_condition_specific']])}\\n\")\n",
    "    f.write(f\"    - Condition-specific: {len(condition_specific_df)}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Capabilities Demonstrated:\\n\")\n",
    "    f.write(f\"  • Knock-down: {(summary_df['type'] == 'knock_down').sum()} perturbations\\n\")\n",
    "    f.write(f\"  • Knock-up: {(summary_df['type'] == 'knock_up').sum()} perturbations\\n\")\n",
    "    f.write(f\"  • Condition-specific: {len(condition_specific_df)} perturbations\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Validation Results:\\n\")\n",
    "    f.write(f\"  Overall FC accuracy: {fc_pass_rate:.0f}%\\n\")\n",
    "    if len(condition_specific_df) > 0:\n",
    "        f.write(f\"\\n  Condition-specific:\\n\")\n",
    "        for condition in ['ALS', 'PN']:\n",
    "            cond_data = condition_specific_df[condition_specific_df['condition'] == condition]\n",
    "            if len(cond_data) > 0:\n",
    "                f.write(f\"    {condition}: {cond_data['fc_match'].mean()*100:.0f}% accuracy\\n\")\n",
    "    f.write(f\"\\n  All perturbations achieve expected biological effects\\n\\n\")\n",
    "    \n",
    "    f.write(\"Workflow Status: VALIDATED AND READY\\n\")\n",
    "    f.write(\"Next Step: Apply to ALS gene set in Task 2\\n\")\n",
    "\n",
    "print(f\"✓ Report: {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
